program logic for https://github.com/twagger/minishell

# approach and components

lexer: takes the input characters and puts the characters together into words called tokens
parser: process tokens according to a grammar to build a command table
expander: expand vars of form ${VAR}, set expand and print env vars
executor: for every simple command, create a new process, pipe between processes, handle redirection (pipex, basically)

## lexer:
takes the input characters and puts the characters together into words called tokens
Lexer performs token recognition, as defined here:
https://pubs.opengroup.org/onlinepubs/9699919799.2018edition/utilities/V3_chap02.html#tag_18_03

## parser:
process tokens according to a grammar to build a command table
Parser performs syntax analysis based on shell grammar, defined here:
https://pubs.opengroup.org/onlinepubs/9699919799.2018edition/utilities/V3_chap02.html#tag_18_10

understanding ms_parser:
= arg 1 is a t_token (a single token pointing to another) produced by ms_tokeniser. I would guess this is the first token in the linked list.
= arg 2 is a parsing table, which was generated by using bison to output a textual automaton using gram.y grammar file, then manually converting

For example, the line : '0 0 0 1 -1' can be read : When you are in the STATE 0, if the token you read from input is a WORD, you must SHIFT this token from the input into the stack, then change the STATE to 1. The last "-1" just means that the last parameter is not relevant for this line.

we initialise the stack, then loop as long as return value is RET_OK:
- get entry from parsing table (find the right entry in the parsing table according to the input and the current state)
- if there is an entry, perform the relevant action (ACT_SHIFT, ACT_REDUCE, ACT_ACCEPT)

State (we are currently in)
- can occur multiple times in the list because what happens next depends on the token type

Token type:
        T_END = -2,
        T_WORD = 0,
        T_RED_TO,
        T_RED_FROM,
        T_DLESS,
        T_DGREAT,
        T_PIPE  
        R_PIPE_SEQUENCE = 100,
        R_SIMPLE_COMMAND,
        R_CMD_NAME,
        R_CMD_WORD,
        R_CMD_PREFIX,
        R_CMD_SUFFIX,
        R_IO_REDIRECT,
        R_IO_FILE,
        R_FILENAME,
        R_IO_HERE,
        R_HERE_END

Actions:
        ACT_SHIFT,
        ACT_REDUCE,
        ACT_ACCEPT,
        ACT_REJECT

Next state:
- why do token types appear in here? (numbers from 100 onward)

Number of reduced tokens:
-1, 1, 2, 3

A stack for storing and accessing the production rules.

There are three actions we can do (see https://www.geeksforgeeks.org/shift-reduce-parser-compiler/)
ACT_SHIFT   This involves moving symbols from the input buffer onto the stack
 Shift the current input into the stack and add the next state on top.

ACT_REDUCE  If the handle appears on top of the stack then, its reduction by using appropriate production rule is done i.e. RHS of a production rule is popped out of a stack and LHS of a production rule is pushed onto the stack.
Pop the stack and replace the popped elements with a reduction. Add the next step on top and complete the output (tree) with the popped elements

ACT_ACCEPT  If only the start symbol is present in the stack and the input buffer is empty then, the parsing action is called accept. When accepted action is obtained, it is means successful parsing is done.
Accept the command line. This will trigger the return of the output to the main function.

ACT_REJECT  If error?
Reject the command line. This will trigger the cleaning of the allocated resources and a NULL return. 

## expander:
expand vars of form ${VAR}, set expand and print env vars

## executor:
for every simple command, create a new process, pipe between processes, handle redirection (pipex, basically)

# functions 

main 			- handle env vars then launch a read loop
ms_loop 		- display a prompt, get a command (ms_readline), call ms_routine to parse and execute, loop
ms_readline		- command line input with prompt, cursor movement and history
ms_routine		- parse and execute (call ms_tokeniser, ms_parser, ms_execute_ast) each line (where a line is the input the user typed in the interpreter)
				  parser can return 1 (command can be run with ms_execute_ast) or NULL (meaning syntax error)
ms_tokeniser	- skip over leading spaces, count line length, get current token (ms_check_each), add to end of linked list, add terminating NULL item to linked list
ms_check_each	- ???
ms_parser		- browse the input and shift or reduce the tokens until the command is accepted or rejected. The parser also produces and returns an output (syntax tree).
ms_get_entry	- find the right entry in the parsing table according to the input and the current state.
ms_shift		- shift the current input into the stack and add the next state on top
ms_reduce		- pop the stack and replace the popped elements with a reduction. Add the next step on top and complete the output (tree) with the popped elements.
ms_accept		- Accept the command line. This will trigger the return of the output to the main function
ms_reject		- Reject the command line. This will trigger the cleaningof the allocated resources and a NULL return. 
ms_execute_ast	- handle heredoc, search ast, execute pipeline, do redirections, execute simple commands

# structs
what is an ast?
